---
title: Minute Prices
icon: stopwatch
description: Real-time minute-by-minute price data for tokens across all supported blockchains
---

# prices.minute

## Overview

The `prices.minute` table provides the most granular price data for tokens across multiple blockchains, with minute-level precision. This is the highest resolution price data available in the Dune platform.

## Table Schema

| Column | Type | Description |
|--------|------|-------------|
| blockchain | varchar | Blockchain identifier (e.g., 'ethereum', 'arbitrum') |
| contract_address | varbinary | Token contract address (fixed address for native tokens) |
| symbol | varchar | Token symbol (e.g., 'ETH', 'USDC') |
| timestamp | timestamp | Minute timestamp |
| price | double | Token price in USD (volume-weighted average) |
| decimals | int | Token decimals |
| volume | double | Trading volume in USD (from price source) |
| source | varchar | Data source ('coinpaprika' or 'dex.trades') |

## Implementation Details

The minute prices are built using a sparse hour interpolation approach:

1. **Source from hourly data**: Uses `prices.hour` as the source instead of raw minute-level data
2. **Linear interpolation**: Implements linear interpolation between hourly anchor points to create smooth minute-level data
3. **Noise reduction**: Reduces noise and outliers by using stable hourly data points as anchors
4. **Forward-filling**: The system forward-fills with the last available price for a maximum of 48 hours (2880 minutes) to avoid stale data
5. **Continuous time series**: Provides minute-by-minute data points for every minute between hourly anchors

This approach ensures more reliable and consistent minute-level pricing while maintaining the granularity needed for high-frequency analysis.

## Usage

This table is ideal for high-frequency analysis and examining short-term price movements. It's particularly useful for studying price impacts of specific events or transactions with high temporal precision.

**Note**: The minute-level data is interpolated from hourly anchor points, providing smooth and consistent pricing while reducing the impact of noise and outliers that can occur in raw minute-level data.

## Latency and Update Frequency

The `prices.minute` table is updated hourly based on the upstream data pipeline. As a result, prices typically have a latency of approximately 1 hour from real-time.

## Usage Examples

Here are some examples of how to use the prices tables.

### Get minute-by-minute ETH prices during a specific event:
```sql
SELECT
  timestamp,
  price
FROM prices.minute
WHERE
  blockchain = 'ethereum'
  AND contract_address = 0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2 -- WETH
  AND timestamp >= NOW() - INTERVAL '2' HOUR
  AND timestamp <= NOW() - INTERVAL '1' HOUR
ORDER BY timestamp
```

### Analyze price volatility within short time frames:
```sql
SELECT
  date_trunc('hour', timestamp) as hour,
  max(price) - min(price) as price_range,
  (max(price) - min(price)) / min(price) * 100 as volatility_pct
FROM prices.minute
WHERE
  blockchain = 'ethereum'
  AND contract_address = 0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2 -- WETH
  AND timestamp >= NOW() - INTERVAL '1' DAY
GROUP BY 1
ORDER BY 1
```

## Data Quality Notes

- Due to its high granularity, queries on this table may be more resource-intensive
- Consider using `prices.hour` or `prices.day` for longer time ranges if minute-level precision is not required
- Native tokens (like ETH, BNB) are assigned fixed addresses for consistency
- Always use `contract_address` and `blockchain` for precise token identification, never use `symbol` for joins or filters
- **Interpolated Pricing**: Minute-level data is interpolated from hourly anchor points, providing smoother and more consistent pricing
- **Reduced Noise**: The interpolation approach reduces the impact of noise and outliers that can occur in raw minute-level data
- **48-Hour Forward-Fill**: The system forward-fills with the last available price for a maximum of 48 hours (2880 minutes) to avoid stale data
- **Data Limitations**: While the interpolation approach improves data quality, users should always validate prices for critical applications